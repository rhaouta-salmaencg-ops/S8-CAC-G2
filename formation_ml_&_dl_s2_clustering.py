python
# -*- coding: utf-8 -*-
"""Formation ML & DL : S2 Clustering

<center><h1>Formation en Machine Learning et Deep Learning</h1></center>
<center><h3>Atelier 2 : Comprendre lâ€™Apprentissage Non SupervisÃ©</h3></center>

**Objectif :**
Initier les apprenants Ã  lâ€™apprentissage non supervisÃ©.
Nous allons utiliser les principaux algorithmes suivants :

â€¢ K-Means : clustering partitionnel  
â€¢ DBSCAN : clustering basÃ© sur la densitÃ©  
â€¢ Clustering hiÃ©rarchique : approche agglomÃ©rative  
â€¢ ModÃ¨le de MÃ©lange de Gaussiennes (GMM - Gaussian Mixture Model)

# Introduction

Lâ€™apprentissage non supervisÃ© est une branche du Machine Learning dont lâ€™objectif est dâ€™analyser et de structurer des donnÃ©es sans Ã©tiquettes prÃ©dÃ©finies (labels).

Contrairement Ã  lâ€™apprentissage supervisÃ©, les donnÃ©es ne contiennent pas dâ€™Ã©tiquettes. Les algorithmes se basent uniquement sur les similaritÃ©s et les structures prÃ©sentes dans les donnÃ©es pour regrouper les observations.

Dans cet atelier, nous allons explorer les mÃ©thodes de clustering, parmi les plus utilisÃ©es en apprentissage non supervisÃ©.

BibliothÃ¨ques :
â€¢ Scikit-learn : bibliothÃ¨que pour lâ€™apprentissage automatique  
â€¢ Matplotlib et Seaborn : outils de visualisation  
"""
Importation des bibliothÃ¨ques
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
ðŸ“ŒChargement du Dataset Iris
from sklearn.datasets import load_iris

dataset = load_iris()
df = pd.DataFrame(dataset.data, columns=dataset.feature_names)

display(df.head())
ðŸ“Œ Visualisation des donnÃ©es
def plot_initial_data():
    plt.figure(figsize=(6,6))
    plt.scatter(df.iloc[:, 0], df.iloc[:, 1], s=50, alpha=0.7)
    plt.title("DonnÃ©es initiales")
    plt.xlabel(dataset.feature_names[0])
    plt.ylabel(dataset.feature_names[1])
    plt.show()

plot_initial_data()
ðŸ”µ K-MEANS
from sklearn.cluster import KMeans

kmeans = KMeans(
    n_clusters=2,
    init="k-means++",
    max_iter=100,
    random_state=42
)

kmeans_labels = kmeans.fit_predict(df)
Visualisation
def plot_clusters(labels, title):
    plt.figure(figsize=(6,6))
    sns.scatterplot(
        x=df.iloc[:,0],
        y=df.iloc[:,1],
        hue=labels,
        palette="viridis",
        s=50
    )
    plt.title(title)
    plt.xlabel(dataset.feature_names[0])
    plt.ylabel(dataset.feature_names[1])
    plt.show()

plot_clusters(kmeans_labels, "K-Means Clustering")
ðŸ“Œ MÃ©thode du coude
inertia = []

for k in range(1, 10):
    model = KMeans(n_clusters=k, random_state=42)
    model.fit(df)
    inertia.append(model.inertia_)

plt.plot(range(1,10), inertia, marker="o")
plt.xlabel("Nombre de clusters")
plt.ylabel("Inertie")
plt.title("MÃ©thode du coude")
plt.show()
ðŸ”µ DBSCAN
from sklearn.cluster import DBSCAN

dbscan = DBSCAN(
    eps=0.5,
    min_samples=5,
    metric="euclidean"
)

dbscan_labels = dbscan.fit_predict(df)

plot_clusters(dbscan_labels, "DBSCAN Clustering")
ðŸ”µ Clustering HiÃ©rarchique
from scipy.cluster.hierarchy import dendrogram, linkage

linked = linkage(df, method="ward")

plt.figure(figsize=(8,5))
dendrogram(linked)
plt.title("Dendrogramme")
plt.show()
from sklearn.cluster import AgglomerativeClustering

agglo = AgglomerativeClustering(
    n_clusters=2,
    metric="euclidean",
    linkage="ward"
)

agglo_labels = agglo.fit_predict(df)

plot_clusters(agglo_labels, "Agglomerative Clustering")
ðŸ”µ GMM
from sklearn.mixture import GaussianMixture

gmm = GaussianMixture(
    n_components=2,
    covariance_type="full",
    max_iter=100,
    random_state=42
)

gmm_labels = gmm.fit_predict(df)

plot_clusters(gmm_labels, "GMM Clustering")
ðŸ”µ Ã‰valuation : Silhouette Score
from sklearn.metrics import silhouette_score

def evaluate_clusters(labels, method):
    score = silhouette_score(df, labels)
    print(f"Silhouette Score ({method}) : {score:.2f}")

evaluate_clusters(kmeans_labels, "K-Means")
evaluate_clusters(dbscan_labels, "DBSCAN")
evaluate_clusters(agglo_labels, "Agglomerative")
evaluate_clusters(gmm_labels, "GMM")
ðŸ–¼ SEGMENTATION Dâ€™IMAGE
ðŸ“Œ Chargement Image
import cv2

image_path = "/content/Feuille.bmp"
image = cv2.imread(image_path)

# Conversion BGR â†’ RGB (correction importante)
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

plt.imshow(image_rgb)
plt.axis("off")
plt.show()
ðŸ“Œ Segmentation niveau de gris
image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

pixels = image_gray.reshape(-1,1)

kmeans = KMeans(n_clusters=2, random_state=42)
labels = kmeans.fit_predict(pixels)

segmented = labels.reshape(image_gray.shape)

binary_image = (segmented * 255).astype(np.uint8)

plt.figure(figsize=(10,5))

plt.subplot(1,2,1)
plt.imshow(image_rgb)
plt.title("Image originale")
plt.axis("off")

plt.subplot(1,2,2)
plt.imshow(binary_image, cmap="gray")
plt.title("Segmentation K-Means")
plt.axis("off")

plt.show()
ðŸ“Œ Segmentation RGB
pixels_rgb = image_rgb.reshape(-1,3)

kmeans = KMeans(n_clusters=2, random_state=42)
labels_rgb = kmeans.fit_predict(pixels_rgb)

segmented_rgb = labels_rgb.reshape(image_rgb.shape[:2])

binary_rgb = (segmented_rgb * 255).astype(np.uint8)

plt.figure(figsize=(10,5))

plt.subplot(1,2,1)
plt.imshow(image_rgb)
plt.title("Image originale")
plt.axis("off")

plt.subplot(1,2,2)
plt.imshow(binary_rgb, cmap="gray")
plt.title("Segmentation RGB")
plt.axis("off")

plt.show()
ðŸ“Œ Segmentation par canal R, G, B
R, G, B = cv2.split(image_rgb)

def segment_channel(channel):
    pixels = channel.reshape(-1,1)
    kmeans = KMeans(n_clusters=2, random_state=42)
    labels = kmeans.fit_predict(pixels)
    return (labels.reshape(channel.shape) * 255).astype(np.uint8)

segR = segment_channel(R)
segG = segment_channel(G)
segB = segment_channel(B)

segmented_imageRGB = cv2.merge([segR, segG, segB])

plt.figure(figsize=(10,5))

plt.subplot(1,2,1)
plt.imshow(image_rgb)
plt.title("Image originale")
plt.axis("off")

plt.subplot(1,2,2)
plt.imshow(segmented_imageRGB)
plt.title("Segmentation par canal RGB")
plt.axis("off")

plt.show()
